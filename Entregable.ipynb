{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7115cdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#Cargue del Dataset y Elimino columnas que no me aportan al modelo \n",
    "Datos = pd.read_excel('mask_info_cli_ros_gmr.xlsx')\n",
    "Datos.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "display(Datos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8948a7",
   "metadata": {},
   "source": [
    "**Se Identifico un Registro mal Ingresado tenia el texto (CAPTURADO POR NARCOTRÁFICO CASO 1086954                                                                        \") se le puso el mismo valor que tenia la columna frecuencia_total_anual_transada__efectivo_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623c7018",
   "metadata": {},
   "outputs": [],
   "source": [
    "Datos['monto_total_anual_transado__efectivo_'] = Datos['monto_total_anual_transado__efectivo_'].replace({'CAPTURADO POR NARCOTRÁFICO CASO 1086954                                                                        \"': 42940000})\n",
    "Datos[\"monto_total_anual_transado__efectivo_\"] = pd.to_numeric(Datos[\"monto_total_anual_transado__efectivo_\"], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7035f17c",
   "metadata": {},
   "source": [
    "## **Reporte Dataset Inicial**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7bbb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install ydata-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2c53eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "from ydata_profiling.utils.cache import cache_file\n",
    "Reporte = ProfileReport(Datos, title=\"Reporte Datos Entregados\", minimal = True)\n",
    "Reporte.to_notebook_iframe()\n",
    "Reporte.to_file(\"ReporteDataset.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58471b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elimino Todas las Columnas que no me aportan al modelo \n",
    "Datos.drop(['nombre','num_caso','cod_ciiu','cod_ocup','cod_ciudad_dirp','cod_pais_nacim','pais_origen_recursos','pais_residencia','cod_categ_lc','riesgo_cliente__ric_','cod_subcateg_lc','cod_nivel_cat'], axis=1, inplace=True)\n",
    "Datos.drop(['act_econom','desc_categ','motivo_ingreso_a_listas_de_control','ros'], axis=1, inplace=True)\n",
    "Datos.drop(['cod_tipo_doc', 'f_vinc', 'f_ingreso_lc'], axis=1, inplace=True)\n",
    "Datos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620a5ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identifico variables categoricas y las Numericas\n",
    "num_cols = Datos.select_dtypes(exclude=['object']).columns\n",
    "cat_cols = Datos.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc135c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "#Imputo Columnas Numericas\n",
    "imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "NumImp = pd.DataFrame(imputer.fit_transform(Datos[num_cols]), columns=Datos[num_cols].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74c77d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputo Columnas Categoricas\n",
    "imputer = SimpleImputer(strategy='constant', fill_value='Sin Informacion')\n",
    "CatImp = pd.DataFrame(imputer.fit_transform(Datos[cat_cols]), columns=Datos[cat_cols].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f090048e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concateno el Dataframe con columnas ya Imputadas\n",
    "Datos = pd.concat([CatImp, NumImp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd250ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para Disminuir la Dimencion de los valores Dividi en rangos estas 6 Columnas\n",
    "columnas = ['ing_mes','egresos_mes','monto_total_anual_transado__efectivo_','monto_total_anual_transado__operaciones_internacionales_','frecuencia_total_anual_transada__operaciones_internacionales_','frecuencia_total_anual_transada__efectivo_']\n",
    "Convertir = Datos[columnas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c575770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para convertir en Rangos \n",
    "def asignar_rangos(df, columnas):\n",
    "    def dividir_en_rangos(col):\n",
    "        valores_unicos = sorted(col.dropna().unique()) # Obtener valores únicos y ordenarlos\n",
    "        total_valores = len(valores_unicos)\n",
    "        if total_valores < 5:\n",
    "            return col.apply(lambda x: \"Rango menor de 5\" if pd.notna(x) else x)\n",
    "        block_size = total_valores // 5 # Definir el tamaño de cada bloque\n",
    "        remainder = total_valores % 5\n",
    "        rangos = []\n",
    "        start = 0\n",
    "        for i in range(5):\n",
    "            end = start + block_size + (1 if i < remainder else 0)\n",
    "            if end > total_valores:\n",
    "                end = total_valores\n",
    "            min_val = valores_unicos[start]\n",
    "            max_val = valores_unicos[end - 1]\n",
    "            rangos.append((min_val, max_val))\n",
    "            start = end\n",
    "        def asignar_rango(valor):\n",
    "            if pd.isna(valor):\n",
    "                return valor\n",
    "            for min_val, max_val in rangos:\n",
    "                if min_val <= valor <= max_val:\n",
    "                    return f\"Rango entre {min_val} y {max_val}\"\n",
    "        return col.apply(asignar_rango)\n",
    "    for columna in columnas:\n",
    "        if columna in df.columns:\n",
    "            df.loc[:, columna] = dividir_en_rangos(df[columna]) \n",
    "    return df\n",
    "Rangos = asignar_rangos(Convertir.copy(), columnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ab635b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elimine las columnas indicadas y adicione las nuevas ya con los rangos\n",
    "Datos.drop(columns=columnas, inplace=True)\n",
    "Datos = pd.concat([Datos, Rangos], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f75534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Genero una Copia de los Datos Ya Preparados\n",
    "DatOrig = Datos.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81675eae",
   "metadata": {},
   "source": [
    "**Preparación para K-prototypes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4860ca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identifico variables categoricas y las Numericas\n",
    "num_cols = Datos.select_dtypes(exclude=['object']).columns\n",
    "cat_cols = Datos.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8d38f4",
   "metadata": {},
   "source": [
    "**Aplicar K-prototypes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da35e51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conversión de DataFrame a matriz de Numpy\n",
    "data_matrix = Datos.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa6bf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asignacion Manual del Total de Cluster\n",
    "num_clusters=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d388e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kmodes.kprototypes import KPrototypes\n",
    "kproto = KPrototypes(n_clusters=num_clusters,init='Huang',n_init=10,max_iter=150,verbose=1)\n",
    "clusters = kproto.fit_predict(data_matrix, categorical=[Datos.columns.get_loc(col) for col in cat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38e415e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añadir la información de clusters al DataFrame original\n",
    "DatOrig['cluster'] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8dd1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrupo por cluster y cuento cuantos registros asigno a cada cluster\n",
    "DatOrig.groupby('cluster').cluster.count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db14e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataOriginal = DatOrig.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b420fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtención de los clusters únicos\n",
    "NumeroCluster = DatOrig[\"cluster\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df641d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista para almacenar los nombres de los datasets segmentados\n",
    "nombres_variables = []\n",
    "for cluster in NumeroCluster:\n",
    "    df_segmentado = DatOrig[DatOrig[\"cluster\"] == cluster]\n",
    "    Ncluster = f\"Cluster_0{cluster}\"\n",
    "    globals()[Ncluster] = df_segmentado\n",
    "    nombres_variables.append(Ncluster)\n",
    "print(\"Datasets segmentados creados exitosamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac00544",
   "metadata": {},
   "outputs": [],
   "source": [
    "todoscluster = []\n",
    "for cluster in NumeroCluster:\n",
    "    Ncluster = f\"Cluster_0{cluster}\"\n",
    "    todoscluster.append(Ncluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8ec829",
   "metadata": {},
   "source": [
    "Adicional tambien Retirare para generar Reglas de Asociacion las columnas:\n",
    "* doc\n",
    "* cluster\n",
    "\n",
    "Tambien Adicionare las Columnas que bancolombia me diga que no son relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c196703",
   "metadata": {},
   "outputs": [],
   "source": [
    "ColumnEli =['doc','cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae7a493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def depura_columnas(nombres_cluster, columnas_eliminar):\n",
    "    for nombre in nombres_cluster:\n",
    "        # Usamos globals() para acceder a la variable con el nombre dinámicamente\n",
    "        if nombre in globals():\n",
    "            df = globals()[nombre]\n",
    "            if isinstance(df, pd.DataFrame):\n",
    "                # Creamos una copia del DataFrame con las columnas eliminadas y la reasignamos a la variable global\n",
    "                globals()[nombre] = df.drop(columns=columnas_eliminar, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f467e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamada a la función\n",
    "depura_columnas(todoscluster, ColumnEli)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead08e97",
   "metadata": {},
   "source": [
    "# **Reporte Analisis Caracteristica Cluster Generado**\n",
    "\n",
    "Este Genera un reporte en texto con el analisis del contenido por cada Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5034335b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_columnas(df):\n",
    "    resultados = []\n",
    "    for columna in df.columns:\n",
    "        value_counts = df[columna].value_counts()\n",
    "        ItmasAlto = value_counts.idxmax()\n",
    "        ValmasAlto = value_counts.max()\n",
    "        total_items = value_counts.sum()\n",
    "        PormasAlto = (ValmasAlto / total_items) * 100\n",
    "        resultado = (f\"De la columna '{columna}': El {PormasAlto:.2f}% de los Registros es '{ItmasAlto}' \"\n",
    "                     f\"Con un total de {ValmasAlto} Items\")\n",
    "        resultados.append(resultado)\n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e05392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardar_resultados_en_archivo(lista_nombres_df, archivo_salida):\n",
    "    with open(archivo_salida, 'w') as file:\n",
    "        for nombre_df in lista_nombres_df:\n",
    "            df = globals().get(nombre_df)\n",
    "            if df is None or not isinstance(df, pd.DataFrame):\n",
    "                print(f\"El DataFrame '{nombre_df}' no existe o no es un DataFrame. Se omite.\")\n",
    "                continue\n",
    "            file.write(f\"Resultados del Cluster '{nombre_df}':\\n\")\n",
    "            resultados = analizar_columnas(df)\n",
    "            for resultado in resultados:\n",
    "                file.write(resultado + \"\\n\")\n",
    "            file.write(\"-\" * 50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdeb380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamar a la función para guardar los resultados en un archivo de texto\n",
    "guardar_resultados_en_archivo(todoscluster, 'Caracterizacion_clusters.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7211cc",
   "metadata": {},
   "source": [
    "# **Reporte de Reglas de Asociacion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "dd40186d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
    "from joblib import Parallel, delayed\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b99c6ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para procesar cada segmento utilizando FP-Growth\n",
    "def procesar_segmento(segmento, min_support=0.01, min_threshold=0.9):\n",
    "    conjuntos_frecuentes = fpgrowth(segmento, min_support=min_support, use_colnames=True)\n",
    "    if conjuntos_frecuentes.shape[0] > 0:\n",
    "        reglas_asociacion = association_rules(conjuntos_frecuentes, metric='confidence', min_threshold=min_threshold)\n",
    "        reglas_con_mas_caracteristicas = reglas_asociacion[reglas_asociacion['antecedents'].apply(lambda x: len(x) >= 2)]\n",
    "        return reglas_con_mas_caracteristicas\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5716f781",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster_name in todoscluster:\n",
    "    Cluster = globals()[cluster_name]\n",
    "    # Binarizar el dataset con OneHotEncoder\n",
    "    encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "    datos_binarizados = encoder.fit_transform(Cluster)\n",
    "    Cluster_binarizado = pd.DataFrame(datos_binarizados, columns=encoder.get_feature_names_out(Cluster.columns))\n",
    "    tamaño_segmento = 100 # Dividir las columnas en segmentos de tamaño especificado (ajustado para one-hot encoding)\n",
    "    segmentos_columnas = [Cluster_binarizado.iloc[:, i:i+tamaño_segmento] for i in range(0, Cluster_binarizado.shape[1], tamaño_segmento)]\n",
    "    # Procesar los segmentos en paralelo\n",
    "    todas_reglas_asociacion = Parallel(n_jobs=-1)(delayed(procesar_segmento)(segmento, min_support=0.1, min_threshold=0.6) for segmento in segmentos_columnas)\n",
    "    # Filtrar reglas vacías\n",
    "    todas_reglas_asociacion = [reglas for reglas in todas_reglas_asociacion if reglas is not None]\n",
    "    # Si se generaron reglas, concatenarlas y aplicar filtros adicionales\n",
    "    if todas_reglas_asociacion:\n",
    "        reglas_asociacion_total = pd.concat(todas_reglas_asociacion, ignore_index=True)\n",
    "        # Aplicar filtros para reducir el número de reglas\n",
    "        reglas_filtradas = reglas_asociacion_total[\n",
    "            (reglas_asociacion_total['support'] >= 0.05) &\n",
    "            (reglas_asociacion_total['confidence'] >= 0.8) &\n",
    "            (reglas_asociacion_total['lift'] >= 1.5)\n",
    "        ]\n",
    "        # Ordenar las reglas por confianza y seleccionar las más fuertes\n",
    "        reglas_filtradas = reglas_filtradas.sort_values(by='confidence', ascending=False)#.head(100)\n",
    "        # Redondear valores para mejor presentación\n",
    "        reglas_filtradas = reglas_filtradas.round(decimals=3)\n",
    "        reglas_filtradas['antecedent support'] = reglas_filtradas['antecedent support'].apply(lambda x: '{:,.0f}'.format(x))\n",
    "        reglas_filtradas['consequent support'] = reglas_filtradas['consequent support'].apply(lambda x: '{:,.0f}'.format(x))\n",
    "        reglas_filtradas['support'] = reglas_filtradas['support'].apply(lambda x: '{:,.0f}'.format(x))\n",
    "        reglas_filtradas['lift'] = reglas_filtradas['lift'].apply(lambda x: '{:,.3f}'.format(x)) \n",
    "        # Definir una función para formatear los frozensets\n",
    "        def format_frozenset(fset):\n",
    "            elements = [elem.strip() for elem in str(fset).strip(\"frozenset({})\").split(\",\")]\n",
    "            return \", \".join(elements)\n",
    "        # Formatear las columnas antecedents y consequents para eliminar \"frozenset({...})\"\n",
    "        reglas_filtradas['antecedents'] = reglas_filtradas['antecedents'].apply(lambda x: format_frozenset(x))\n",
    "        reglas_filtradas['consequents'] = reglas_filtradas['consequents'].apply(lambda x: format_frozenset(x))\n",
    "        # Exportar el dataframe a un archivo CSV\n",
    "        reglas_filtradas.to_csv(f'Reglas_Asociacion_{cluster_name}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
